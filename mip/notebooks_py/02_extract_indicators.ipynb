{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Museums in the Pandemic - Extract indicators\n",
    "\n",
    "**Authors**: Andrea Ballatore (KCL)\n",
    "\n",
    "**Abstract**: Extract indicators from museum text. The indicators are generated from the app with option `an_text`.\n",
    "\n",
    "## Setup\n",
    "This is to check that your environment is set up correctly (it should print 'env ok', ignore warnings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda env: mip_v1\n",
      "2.3.5\n",
      "/Users/andreaballatore/Dropbox/DRBX_Docs/Work/Projects/github_projects/museums-in-the-pandemic/mip/notebooks_py\n",
      "Warning: .secrets.json file not found to use Twitter API.\n",
      "Warning: .secrets.json file not found to use Crowdtangle API.\n",
      "env ok\n"
     ]
    }
   ],
   "source": [
    "# Test geospatial libraries\n",
    "# check environment\n",
    "import os\n",
    "print(\"Conda env:\", os.environ['CONDA_DEFAULT_ENV'])\n",
    "if os.environ['CONDA_DEFAULT_ENV'] != 'mip_v1':\n",
    "    raise Exception(\"Set the environment 'mip_v1' on Anaconda. Current environment: \" + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "# spatial libraries \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import glob\n",
    "import spacy\n",
    "print(spacy.__version__)\n",
    "from termcolor import colored\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "#import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "#import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import from `mip` project\n",
    "print(os.getcwd())\n",
    "fpath = os.path.abspath('../')\n",
    "if not fpath in sys.path:\n",
    "    sys.path.insert(0, fpath)\n",
    "\n",
    "out_folder = '../../'\n",
    "\n",
    "from museums import *\n",
    "from museums import get_museums_w_web_urls, get_twitter_facebook_links, load_input_museums_wattributes, get_extra_museum_attributes\n",
    "from utils import _is_number, write_file\n",
    "from analytics.text_models import derive_new_attributes_matches, get_all_matches_from_db, get_indicator_annotations, derive_new_attributes_matches\n",
    "from scrapers.scraper_websites import get_scraping_session_tables, get_session_id_from_table_name\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "print('env ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DB\n",
    "\n",
    "It needs the DCS VPN active to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open connection to DB\n",
    "from db.db import connect_to_postgresql_db\n",
    "\n",
    "db_conn = connect_to_postgresql_db()\n",
    "print(\"DB connected\")\n",
    "\n",
    "def get_all_sessions():\n",
    "    return sorted([get_session_id_from_table_name(x) for x in get_scraping_session_tables(db_conn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract matches for all museum websites\n",
    "\n",
    "Using the best deep learning model defined above, find indicators for all museums (from websites and social media).\n",
    "\n",
    "The manual annotation data with 700 cases is in `matches_valid_ann_df_v3.pik`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load deep learning validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def remove_duplicate_matches(df):\n",
    "    # find duplicates\n",
    "    n = len(df)\n",
    "    df = df.drop_duplicates(subset=df.columns.difference(['page_id','sentence_id']))\n",
    "    print('remove_duplicate_matches:',n,len(df))\n",
    "    return df\n",
    "\n",
    "def prep_match_data(df):\n",
    "    for c in valid_model_columns:\n",
    "        if not c in df.columns:\n",
    "            print(\"Warning: column '{}' is missing, adding a zero column\".format(c))\n",
    "            df[c] = 0\n",
    "    \n",
    "    df = remove_duplicate_matches(df)\n",
    "    df = df[valid_model_columns]\n",
    "    assert len(df.columns) == 33, len(df.columns)\n",
    "    num_df = df.select_dtypes(include=[np.number])\n",
    "    scaler = MinMaxScaler()\n",
    "    # fit and transform in one step\n",
    "    cols = num_df.columns\n",
    "    x_data = pd.DataFrame(scaler.fit_transform(num_df),columns=cols)\n",
    "    return x_data\n",
    "\n",
    "def convert_pred_to_bool(vals):\n",
    "    pred_y = (vals > 0.5).astype(\"bool\")\n",
    "    # unpack results\n",
    "    bool_vals = [item for sublist in pred_y for item in sublist]\n",
    "    return bool_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL COLUMNS\n",
    "cols_fn = out_folder+\"data/analysis/matching_validation/matching_validation_deep_learning_model_columns.csv\"\n",
    "valid_model_columns = pd.read_csv(cols_fn).iloc[:, 0].tolist()\n",
    "\n",
    "valid_ann_df_fn = 'matches_valid_ann_df_v3.pik'\n",
    "valid_ann_df = pd.read_pickle(out_folder+'data/annotations/'+valid_ann_df_fn)\n",
    "\n",
    "valid_match_cnn_model = load_model(out_folder+\"data/analysis/matching_validation/matching_validation_deep_learning_model.h5\")\n",
    "valid_match_cnn_model\n",
    "\n",
    "x_data = prep_match_data(valid_ann_df)\n",
    "assert len(x_data.columns) == 33, len(x_data.columns)\n",
    "print(x_data)\n",
    "pred_valid = convert_pred_to_bool(valid_match_cnn_model.predict(x_data))\n",
    "\n",
    "valid_ann_df['predicted_valid'] = pred_valid\n",
    "\n",
    "#valid_ann_df.to_excel(out_folder+\"tmp/check_deeplearning.xlsx\",index=False)\n",
    "valid_ann_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggr_indicators_by_indic(df):\n",
    "    d = {}\n",
    "    for c in ['indicator_code']:\n",
    "        d[c] = df[c].tolist()[0]\n",
    "    d['cases_700'] = len(df)\n",
    "    d['precision'], d['recall'], d['fscore'], support = precision_recall_fscore_support(df.valid_match_b, df.predicted_valid, average='binary')\n",
    "    confmat = confusion_matrix(df.valid_match_b, df.predicted_valid, normalize='all')\n",
    "    if len(confmat)>1:\n",
    "        d['tn'], d['fp'], d['fn'], d['tp'] = confmat.ravel()\n",
    "    for k,v in d.items():\n",
    "        d[k] = [v]\n",
    "        \n",
    "    res = pd.DataFrame.from_dict(d)\n",
    "    return res\n",
    "\n",
    "# extract indicator stats\n",
    "#indf2 = valid_ann_df.indicator_code.value_counts().to_frame('valid_set_700_cases')\n",
    "#indf2['indicator_code'] = indf2.index\n",
    "#indf2\n",
    "\n",
    "indf2 = pd.DataFrame()\n",
    "for indic,subdf in valid_ann_df.groupby('indicator_code'):\n",
    "    indf2 = indf2.append(aggr_indicators_by_indic(subdf))\n",
    "indf2 = indf2.round(3)\n",
    "indf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all matches from DB (slow)\n",
    "\n",
    "- Dump all matches from DB, after running `an_text` on ALL museums for a given crawling session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DB columns:\n",
    "\"\"\" \n",
    "example_id indicator_code lemma_n lemma_n_wdupl token_n token_n_wdupl criticalwords_n criticalwords_n_wdupl sentence_id  sent_len\n",
    "example_len example_crit_len ann_overlap_lemma ann_overlap_token ann_overlap_criticwords txt_overlap_lemma\n",
    "txt_overlap_token ann_ex_tokens ann_ex_tokens page_tokens session_id page_id muse_id keep_stopwords\n",
    "\"\"\"\n",
    "sessions = get_all_sessions()\n",
    "sessions = ['20210304','20210404','20210629','20210914','20210503','20210614','20210712','20210809','20211108']\n",
    "sessions.extend(['20211206','20220103','20220131','20220228','20220328','20220425','20220524']) # 2022 sessions\n",
    "sessions = sorted(sessions)\n",
    "print(\"target sessions:\", sessions)\n",
    "\n",
    "# get all sessions from DB (slow)\n",
    "if False: # debug\n",
    "    for session_id in sessions:\n",
    "        get_all_matches_from_db(session_id, db_conn, out_folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Predict and save valid matches\n",
    "\n",
    "Load matches from `../../tmp/matches_dump_df_<session>.pik`\n",
    "\n",
    "Dump results in file `../../tmp/all_valid_matches_dump_df.pik`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sessions = ['20210304','20210404']\n",
    "\n",
    "def select_and_merge_indicators(df):\n",
    "    \"\"\" based on `indicator_code_stats_validation-v2.xlsx` \"\"\"\n",
    "    print('select_and_merge_indicators',df.shape)\n",
    "    # drop invalid indicators\n",
    "    invalid_indics = ['closed_perm','finance_health','funding_did_not_get',\n",
    "                     'funding_other_emer','lang_difficulty','made_covid_safe',\n",
    "                     'open_cafe','open_onlineshop','project_postpone',\n",
    "                      'staff_hiring','staff_restruct']\n",
    "    vdf = df[~df['indicator_code'].isin(invalid_indics)].copy()\n",
    "    \n",
    "    # merge indicators\n",
    "    merged_indic = {'online_event':'online_engag',\n",
    "                    'online_exhib':'online_engag',\n",
    "                    'reopen_plan':'reopen_intent',\n",
    "                    'funding_fundraise':'funding',\n",
    "                    'funding_gov_emer':'funding',\n",
    "                    'closed_indef':'closed_cur'}\n",
    "    indicator_code_merged = vdf['indicator_code'].replace(merged_indic)\n",
    "    vdf.loc[:,['indicator_code_merged']]=indicator_code_merged\n",
    "    # compare results\n",
    "    print(df['indicator_code'].value_counts())\n",
    "    print(vdf['indicator_code_merged'].value_counts())\n",
    "    print('  select_and_merge_indicators filtered:',vdf.shape)\n",
    "    return vdf\n",
    "\n",
    "def select_valid_matches(df, model):\n",
    "    \"\"\" use Deep Learning model to validate matches \"\"\"\n",
    "    x_data = prep_match_data(df)\n",
    "    \n",
    "    print('select_valid_matches', x_data.shape)\n",
    "    # check column order\n",
    "    assert valid_model_columns == x_data.columns.tolist()\n",
    "    print(x_data.shape)\n",
    "    # apply model for predictions\n",
    "    valid_int = model.predict(x_data)\n",
    "    pred_valid = convert_pred_to_bool(valid_int)\n",
    "    #print(type(pred_valid),len(pred_valid))\n",
    "    df['valid_match'] = pred_valid\n",
    "    print(df.valid_match.value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(valid_model_columns) > 0\n",
    "allsess_match_df = pd.DataFrame(columns=valid_model_columns)\n",
    "\n",
    "print('sessions:', sessions)\n",
    "for session_id in sessions:\n",
    "    print('\\n> session_id',session_id)\n",
    "    matches_fn = out_folder+'tmp/matches_dump_df_{}.pik'.format(session_id)\n",
    "    matchdf = pd.read_pickle(matches_fn)\n",
    "    matchdf = remove_duplicate_matches(matchdf)\n",
    "    #matchdf = matchdf.sample(100) # DEBUG\n",
    "    print(\"\\t\", matches_fn, matchdf.shape)\n",
    "    # apply model to get valid matches\n",
    "    validmatch_df = select_valid_matches(matchdf, valid_match_cnn_model)\n",
    "    # save sample to inspect results\n",
    "    #validmatch_df.sample(200).to_csv(out_folder+'tmp/valid_matches_sample_{}.tsv'.format(session_id),sep='\\t')\n",
    "    # save results\n",
    "    allsess_match_df = pd.concat([allsess_match_df, validmatch_df])\n",
    "    del validmatch_df\n",
    "\n",
    "print('...merging indicators...')\n",
    "allsess_match_df2 = select_and_merge_indicators(allsess_match_df)\n",
    "print('...removing duplicates...')\n",
    "allsess_match_df2 = remove_duplicate_matches(allsess_match_df2)\n",
    "all_vmatches_fn = out_folder+'tmp/all_valid_matches_dump_df.pik'\n",
    "print(\"valid matches vs invalid\\n\", allsess_match_df2.valid_match.value_counts())\n",
    "print(\"sessions\\n\", allsess_match_df2.session_id.value_counts())\n",
    "valdf = allsess_match_df2[allsess_match_df2.valid_match]\n",
    "valdf.to_pickle(all_vmatches_fn)\n",
    "print('valid matches for all sessions:', len(valdf), all_vmatches_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allsess_match_df)\n",
    "allsess_match_df['valid_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(allsess_match_df.columns)\n",
    "print(\"Matches from DB:\")\n",
    "round(allsess_match_df['valid_match'].value_counts()/len(allsess_match_df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Aggregate indicators for extra evaluation]\n",
    "\n",
    "This section extends and finalises the validation in notebook 01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(allsess_match_df) > 0\n",
    "allsess_match_valid_df = allsess_match_df[allsess_match_df.valid_match]\n",
    "allsess_match_valid_df = remove_duplicate_matches(allsess_match_valid_df)\n",
    "print(\"N =\", len(allsess_match_valid_df))\n",
    "print(\"N museums =\", len(allsess_match_valid_df.muse_id.unique()))\n",
    "allsess_match_valid_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load annotations\n",
    "indic_df, ann_df = get_indicator_annotations(out_folder)\n",
    "del indic_df\n",
    "# calculate n_indic_all_ann_examples\n",
    "ann_stats_df = ann_df.groupby(['indicator_code']).size().reset_index(name='n_indic_all_ann_examples')\n",
    "print(ann_df.head(30))\n",
    "ann_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate precision of matching by indicator\n",
    "\n",
    "This is to evaluate the performance by indicator to account for the high variability, as suggested by AP. \n",
    "\n",
    "- The results are in `indicator_code_stats_validation-v1.xlsx`. \n",
    "- Some indicators were removed.\n",
    "- An extra evaluation was designed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get indicator stats\n",
    "\n",
    "def aggr_indicators_by_indic_allmatches(df):\n",
    "    d = {}\n",
    "    for c in ['indicator_code']:\n",
    "        d[c] = df[c].tolist()[0]\n",
    "    d['matches_ml_true'] = len(df)\n",
    "    d['matches_ml_tot'] = len(allsess_match_df)\n",
    "    d['matches_ml_pc'] = round(d['matches_ml_true'] / d['matches_ml_tot'],3)\n",
    "    d['precision'], d['recall'], d['fscore'], support = precision_recall_fscore_support(df.valid_match_b, df.predicted_valid, average='binary')\n",
    "    confmat = confusion_matrix(df.valid_match_b, df.predicted_valid, normalize='all')\n",
    "    if len(confmat)>1:\n",
    "        d['tn'], d['fp'], d['fn'], d['tp'] = confmat.ravel()\n",
    "    for k,v in d.items():\n",
    "        d[k] = [v]\n",
    "        \n",
    "    res = pd.DataFrame.from_dict(d)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indf3 = pd.DataFrame()\n",
    "for indic,subdf in allsess_match_df.groupby('indicator_code'):\n",
    "    indf3 = indf3.append(aggr_indicators_by_indic_allmatches(subdf))\n",
    "\n",
    "indf3 = indf3.reset_index()\n",
    "indf3 = indf3.merge(indf2,on='indicator_code',how='outer')\n",
    "indf3 = indf3.merge(ann_stats_df,on='indicator_code',how='outer')\n",
    "indf3.to_excel(out_folder+'tmp/indicator_code_stats_validation.xlsx',index=False)\n",
    "indf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Aggregate indicator stats by sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_aggr = ['muse_id','session_id','page_id','indicator_code','n_indic_all_ann_examples']\n",
    "\n",
    "def aggr_indicators_sent(df):\n",
    "    d = {}\n",
    "    for c in col_aggr:\n",
    "        d[c] = df[c].tolist()[0]\n",
    "    d['n_uniq_sentences'] = df['sentence_id'].nunique()\n",
    "    d['n_matched_annotations'] = df['example_id'].nunique()\n",
    "    d['n_matches'] = len(df)\n",
    "    d['matches_to_sent_ratio'] = round(d['n_matches'] / d['n_uniq_sentences'],3)\n",
    "    d['matches_to_example_ratio'] = round(d['n_matches'] / d['n_indic_all_ann_examples'],3)\n",
    "    #d['matches_ratio'] = round(d['n_matches'] / d['n_indic_all_ann_examples'],3)\n",
    "    return pd.Series(d)\n",
    "\n",
    "n = len(allsess_match_valid_df)\n",
    "allsess_match_valid_df2 = allsess_match_valid_df.merge(ann_stats_df, on='indicator_code')\n",
    "assert n == len(allsess_match_valid_df2)\n",
    "\n",
    "muse_indic_sent_df = allsess_match_valid_df2.groupby(col_aggr).apply(aggr_indicators_sent)\n",
    "print(muse_indic_sent_df.columns)\n",
    "muse_indic_sent_df.reset_index(drop=True, inplace=True)\n",
    "muse_indic_sent_df = muse_indic_sent_df.sort_values(['session_id','muse_id','indicator_code'])\n",
    "#print(muse_indic_sent_df.session_id.value_counts())\n",
    "muse_indic_sent_df.to_excel(out_folder+'tmp/museum_indicators_sent_stats-v1.xlsx', index=False)\n",
    "muse_indic_sent_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Museum indic matches sample for extra validation - v1\n",
    "\n",
    "Annotations done in `museum_website_match_sample10_summary-v1.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musem_sample_ids = muse_indic_sent_df.muse_id.sample(10,random_state=10)\n",
    "muse_sample_df = muse_indic_sent_df[muse_indic_sent_df.muse_id.isin(musem_sample_ids)]\n",
    "muse_sample_df.to_excel(out_folder+'tmp/museum_website_match_sample10_summary.xlsx',index=False)\n",
    "allsess_match_valid_df[allsess_match_valid_df.muse_id.isin(musem_sample_ids)].to_excel(out_folder+'tmp/museum_website_match_sample10_matches.xlsx',index=False)\n",
    "\n",
    "muse_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Museum indic matches sample for extra validation - v2\n",
    "\n",
    "- Select random sample from museums where matches > 0, 5 museums for 2 snapshots, for cases that need more investigation in `indicator_code_stats_validation-v1`\n",
    "- Indicators to include: finance_health, lang_difficulty, staff_working\n",
    "- Finance_health appears only in 2 museums, so we will discard it.\n",
    "- The sample is in\n",
    "  - `museum_website_match_sample5_lang_staff_summary-v1.xlsx`: stats for the 10 museums.\n",
    "  - `museum_website_match_sample5_lang_staff-v1.xlsx`: sample of 200 detailed matches.\n",
    "  \n",
    "- The manual annotations are in `museum_website_match_sample5_lang_staff-v2.xlsx` and `museum_website_match_sample5_lang_staff_summary-v2.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(allsess_match_valid_df) > 0\n",
    "assert len(allsess_match_df) > 0\n",
    "\n",
    "print('allsess_match_valid_df N =',len(allsess_match_valid_df))\n",
    "\n",
    "df = allsess_match_valid_df[['muse_id','indicator_code']].drop_duplicates()\n",
    "muse_indic_df = df['indicator_code'].value_counts()\n",
    "print(muse_indic_df)\n",
    "del df\n",
    "\n",
    "random.seed(422)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res_all = pd.DataFrame()\n",
    "for indic in ['lang_difficulty', 'staff_working']:\n",
    "    print('\\n>> indicator:', indic)\n",
    "    mus_df = allsess_match_valid_df[allsess_match_valid_df['indicator_code'] == indic]\n",
    "    mus_df2 = allsess_match_df[allsess_match_df['indicator_code'] == indic]\n",
    "    mus_ids = random.sample(list(mus_df.muse_id.unique()), 5)\n",
    "    print(mus_ids)\n",
    "    # get sample for annotation\n",
    "    sample_df = mus_df2[mus_df2.muse_id.isin(mus_ids)]\n",
    "    print(len(sample_df))\n",
    "    print(sample_df.valid_match.value_counts())\n",
    "    #if indic == 'lang_difficulty':\n",
    "    #    df1 = sample_df[sample_df.valid_match]\n",
    "    #    neg_df = sample_df[sample_df.valid_match==False]\n",
    "    #    print('XXX', len(neg_df), len(df1))\n",
    "    #    df1.append(neg_df.sample(92))\n",
    "    #else:\n",
    "    df1 = sample_df.sample(100)\n",
    "    \n",
    "    res_all = res_all.append(sample_df)\n",
    "    print('\\nSample', len(df1), df1.valid_match.value_counts())\n",
    "    print(df1['muse_id'].unique())\n",
    "    print(df1['session_id'].unique())\n",
    "    res = res.append(df1)\n",
    "    del df1, mus_df2\n",
    "\n",
    "# add stats\n",
    "res_all = res_all.merge(ann_stats_df,on='indicator_code')\n",
    "\n",
    "# generate detailed results\n",
    "res.to_excel(out_folder+'tmp/museum_website_match_sample5_lang_staff.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate summary\n",
    "res_all\n",
    "print(col_aggr)\n",
    "df3 = res_all.groupby(col_aggr).apply(aggr_indicators_sent)\n",
    "df3.to_excel(out_folder+'tmp/museum_website_match_sample5_lang_staff_summary.xlsx',index=False)\n",
    "del df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating precision of extra validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load extra validation for language_difficulty and staff_working\n",
    "vdf = pd.read_excel(out_folder+'data/annotations/museum_website_match_sample5_lang_staff-v2.xlsx')\n",
    "print(len(vdf))\n",
    "\n",
    "vdf['predicted_valid'] = vdf.valid_match\n",
    "vdf['valid_match_b'] = vdf['valid_PW'].map({'T': True, 'F': False})\n",
    "vdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indf4 = pd.DataFrame()\n",
    "for indic,df in vdf.groupby('indicator_code'):\n",
    "    d = {}\n",
    "    for c in ['indicator_code']:\n",
    "        d[c] = df[c].tolist()[0]\n",
    "    d['cases_700'] = len(df)\n",
    "    print(df.columns)\n",
    "    d['precision'], d['recall'], d['fscore'], support = precision_recall_fscore_support(df.valid_match_b, df.predicted_valid, average='binary')\n",
    "    confmat = confusion_matrix(df.valid_match_b, df.predicted_valid, normalize='all')\n",
    "    if len(confmat) > 1:\n",
    "        d['tn'], d['fp'], d['fn'], d['tp'] = confmat.ravel()\n",
    "    for k,v in d.items():\n",
    "        d[k] = [v]\n",
    "        \n",
    "    res = pd.DataFrame.from_dict(d)\n",
    "    indf4 = indf4.append(res)\n",
    "\n",
    "indf4 = indf4.reset_index()\n",
    "indf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.read_excel(out_folder+'data/annotations/museum_website_match_sample10_summary-v1.xlsx')\n",
    "sum_df['valid'] = sum_df['2nd Validator (ap)'].map({'T': True, 'F': False})\n",
    "print(len(sum_df))\n",
    "\n",
    "indf2 = pd.DataFrame()\n",
    "for indic, df in sum_df.groupby('indicator_code'):\n",
    "    d = {'indicator_code': indic}\n",
    "    d['cases_n'] = len(df)\n",
    "    #print(df.columns)\n",
    "    #d['precision'], d['recall'], d['fscore'], support = precision_recall_fscore_support(df.valid_match_b, df.predicted_valid, average='binary')\n",
    "    #confmat = confusion_matrix(df.valid_match_b, df.predicted_valid, normalize='all')\n",
    "    #if len(confmat) > 1:\n",
    "    #    d['tn'], d['fp'], d['fn'], d['tp'] = confmat.ravel()\n",
    "    tdf = df[df['valid']]\n",
    "    fdf = df[~df['valid']]\n",
    "    d['cases_true'] = len(tdf)\n",
    "    d['cases_false'] = len(fdf)\n",
    "    d['indic_mus_accuracy'] = d['cases_true']/d['cases_n']\n",
    "    for k,v in d.items():\n",
    "        d[k] = [v]\n",
    "    res = pd.DataFrame.from_dict(d).round(2)\n",
    "    indf2 = indf2.append(res)\n",
    "\n",
    "# add extra validation\n",
    "#Staff_working\t6\t2\t75%\n",
    "#Language_of_difficulty\t6\t3\t67%\n",
    "\n",
    "indf2 = indf2.append(pd.DataFrame({'indicator_code':['lang_difficulty'], 'indic_mus_accuracy':[.67]}))\n",
    "\n",
    "indf2 = indf2.sort_values('indicator_code').reset_index()\n",
    "indf2.to_excel(out_folder+'tmp/indicator_code_stats_validation-v3.xlsx',index=False)\n",
    "indf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra validation social media indicators - 14 Jan 2022\n",
    "\n",
    "File annotated by AP and PW to make sure social media indicators are identified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn = out_folder+'data/analysis/indicators_social/valid_social_matches_dump_df_valid_debug-v3.xlsx'\n",
    "eval_df = pd.read_excel(eval_fn)\n",
    "eval_df\n",
    "print(eval_df.columns)\n",
    "eval_df['match_valid_manual'] = eval_df['match_valid'].map({'T': True, 'F': False})\n",
    "df = eval_df\n",
    "#display(df)\n",
    "confmat = confusion_matrix(df.match_valid_manual, df.valid_match_machine, normalize='all')\n",
    "d = {}\n",
    "if len(confmat)>1:\n",
    "    d['tn'], d['fp'], d['fn'], d['tp'] = confmat.ravel()\n",
    "\n",
    "d = {key : round(d[key], 2) for key in d}\n",
    "print(d)\n",
    "acc = (d['tn']+d['tp'])\n",
    "print('accuracy:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of valid indicators\n",
    "\n",
    "Based on the validation on the validation by indicator and by museum discussed above, these are the selected indicators.\n",
    "Main file: summary of indicator validation statistics on MS Teams: `indicator_code_stats_validation-v2.xlsx`.\n",
    "\n",
    "**Summary of validation process**\n",
    "- Three iterations of 700 matches for all indicators. Eval data v3 includes sem_similarity and critical_words). THe sample was stratified over overlap value on two groups: low and high values, to ensure that the sample contained enough TRUE cases (`[0, .45, 1.01]`). Result: 70% false, 30% true (TBC).\n",
    "- Intially, we calculated the overall performance metrics, but then we realised that there was high inter-indicator variability.\n",
    "- Sample at the museum level, as opposed to the single indicator level. Sample of 10 random museums including all matches for two time slots (Museum indic matches sample for extra validation - v1). PW and AP annotated the sample. The resulting metrics were generated in `indicator_code_stats_validation-v1.xlsx`.\n",
    "- We selected indicators (YES/NO/merge/further investigation).\n",
    "- Sample only for `finance_health, lang_difficulty, staff_working`, 5 random museums with non-zero matches  for each indicator (100 matches for each of the three groups).\n",
    "\n",
    "\n",
    "**Inclusion criteria**:\n",
    "- No. of cases in the evaluation dataset (reflecting distribution of complete data): > 10 cases\n",
    "- Precision: > .7 (exception: `online_event`)\n",
    "- Recall: no minimum\n",
    "- F-score: no minimum\n",
    "- Accuracy (by museum): > .67\n",
    "\n",
    "**Merge criteria** (for 5 indicators):\n",
    "- recall is less important because we are looking for trends over time, not absolute counts.\n",
    "- precision > .8 (exception: `online_event`)\n",
    "- semantic ambiguity (the two indicators are indistinguishable)\n",
    "\n",
    "**Decision**:\n",
    "- Valid indicators: `closed_cur funding_fundraise funding_gov_emer online_engag open_cur open_onlineshop reopen_intent`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise and viz indicators (websites)\n",
    "\n",
    "Load and viz indicators from `../../tmp/all_valid_matches_dump_df.pik`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119259, 43)\n",
      "20210404    84366\n",
      "20210304    83330\n",
      "20210503    83128\n",
      "20210614    79100\n",
      "20210629    78419\n",
      "20210712    74816\n",
      "20210809    70358\n",
      "20220103    64095\n",
      "20210914    64058\n",
      "20220131    63991\n",
      "20211108    63496\n",
      "20220228    62847\n",
      "20220328    62292\n",
      "20211206    62278\n",
      "20220425    61599\n",
      "20220524    61086\n",
      "Name: session_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../data/analysis/indicators/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indf = pd.read_pickle(\"../../tmp/all_valid_matches_dump_df.pik\")\n",
    "print(indf.shape)\n",
    "#indf = indf.sample(500) # DEBUG\n",
    "print(indf['session_id'].value_counts())\n",
    "\n",
    "indf.sample(10)\n",
    "\n",
    "an_folder = out_folder+'data/analysis/indicators/'\n",
    "an_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All indicators over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>muse_id</th>\n",
       "      <th>indicator_code_merged</th>\n",
       "      <th>n_indicator_matches</th>\n",
       "      <th>session_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210304</td>\n",
       "      <td>domus.NE043</td>\n",
       "      <td>closed_cur</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210304</td>\n",
       "      <td>domus.NE043</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210304</td>\n",
       "      <td>domus.NE043</td>\n",
       "      <td>open_cur</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210304</td>\n",
       "      <td>domus.NE043</td>\n",
       "      <td>reopen_intent</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210304</td>\n",
       "      <td>mm.MDN.006</td>\n",
       "      <td>closed_cur</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177412</th>\n",
       "      <td>20220524</td>\n",
       "      <td>mm.wiki.504</td>\n",
       "      <td>funding</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177413</th>\n",
       "      <td>20220524</td>\n",
       "      <td>mm.wiki.504</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177414</th>\n",
       "      <td>20220524</td>\n",
       "      <td>mm.wiki.504</td>\n",
       "      <td>reopen_intent</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177415</th>\n",
       "      <td>20220524</td>\n",
       "      <td>mm.wiki.505</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177416</th>\n",
       "      <td>20220524</td>\n",
       "      <td>mm.wiki.505</td>\n",
       "      <td>open_cur</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177417 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id      muse_id indicator_code_merged  n_indicator_matches  \\\n",
       "0        20210304  domus.NE043            closed_cur                    7   \n",
       "1        20210304  domus.NE043          online_engag                    2   \n",
       "2        20210304  domus.NE043              open_cur                    1   \n",
       "3        20210304  domus.NE043         reopen_intent                    4   \n",
       "4        20210304   mm.MDN.006            closed_cur                   11   \n",
       "...           ...          ...                   ...                  ...   \n",
       "177412   20220524  mm.wiki.504               funding                    1   \n",
       "177413   20220524  mm.wiki.504          online_engag                    3   \n",
       "177414   20220524  mm.wiki.504         reopen_intent                    1   \n",
       "177415   20220524  mm.wiki.505          online_engag                    4   \n",
       "177416   20220524  mm.wiki.505              open_cur                    1   \n",
       "\n",
       "       session_time  \n",
       "0        2021-03-04  \n",
       "1        2021-03-04  \n",
       "2        2021-03-04  \n",
       "3        2021-03-04  \n",
       "4        2021-03-04  \n",
       "...             ...  \n",
       "177412   2022-05-24  \n",
       "177413   2022-05-24  \n",
       "177414   2022-05-24  \n",
       "177415   2022-05-24  \n",
       "177416   2022-05-24  \n",
       "\n",
       "[177417 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sessionid_to_time(session_id):\n",
    "    dd = datetime.strptime(session_id, '%Y%m%d')\n",
    "    return dd\n",
    "\n",
    "mus_indic_df = indf.groupby(['session_id','muse_id','indicator_code_merged'], as_index=False).size()\n",
    "mus_indic_df = mus_indic_df.rename(columns={'size':'n_indicator_matches'})\n",
    "#mus_indic_df['mus_websites_n'] = mus_indic_df['muse_id'].nunique()\n",
    "mus_indic_df['session_time'] = mus_indic_df['session_id'].apply(sessionid_to_time)\n",
    "mus_indic_df.to_excel(an_folder+'museums_indicators_sessions.xlsx',index=False)\n",
    "mus_indic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>n_sess_museums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210304</td>\n",
       "      <td>3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210404</td>\n",
       "      <td>3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210503</td>\n",
       "      <td>3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210614</td>\n",
       "      <td>3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210629</td>\n",
       "      <td>3057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20210712</td>\n",
       "      <td>3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20210809</td>\n",
       "      <td>3042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20210914</td>\n",
       "      <td>3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20211108</td>\n",
       "      <td>3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20211206</td>\n",
       "      <td>3026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20220103</td>\n",
       "      <td>3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20220131</td>\n",
       "      <td>3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20220228</td>\n",
       "      <td>3038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20220328</td>\n",
       "      <td>3034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20220425</td>\n",
       "      <td>3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20220524</td>\n",
       "      <td>3023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  n_sess_museums\n",
       "0    20210304            3018\n",
       "1    20210404            3032\n",
       "2    20210503            3043\n",
       "3    20210614            3056\n",
       "4    20210629            3057\n",
       "5    20210712            3050\n",
       "6    20210809            3042\n",
       "7    20210914            3047\n",
       "8    20211108            3043\n",
       "9    20211206            3026\n",
       "10   20220103            3032\n",
       "11   20220131            3029\n",
       "12   20220228            3038\n",
       "13   20220328            3034\n",
       "14   20220425            3027\n",
       "15   20220524            3023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus_indic_unique_df = mus_indic_df.groupby(['session_id'], as_index=False).nunique()\n",
    "mus_indic_unique_df = mus_indic_unique_df.rename(columns={'muse_id':'n_sess_museums'})\n",
    "mus_indic_unique_df = mus_indic_unique_df[['session_id','n_sess_museums']]\n",
    "mus_indic_unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>indicator_code_merged</th>\n",
       "      <th>n_museums</th>\n",
       "      <th>n_sess_museums</th>\n",
       "      <th>indic_museum_pc</th>\n",
       "      <th>session_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210304</td>\n",
       "      <td>closed_cur</td>\n",
       "      <td>2253</td>\n",
       "      <td>3018</td>\n",
       "      <td>74.7</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210304</td>\n",
       "      <td>funding</td>\n",
       "      <td>1115</td>\n",
       "      <td>3018</td>\n",
       "      <td>36.9</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210304</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>2701</td>\n",
       "      <td>3018</td>\n",
       "      <td>89.5</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210304</td>\n",
       "      <td>open_cur</td>\n",
       "      <td>1477</td>\n",
       "      <td>3018</td>\n",
       "      <td>48.9</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210304</td>\n",
       "      <td>reopen_intent</td>\n",
       "      <td>2421</td>\n",
       "      <td>3018</td>\n",
       "      <td>80.2</td>\n",
       "      <td>2021-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>20220524</td>\n",
       "      <td>funding</td>\n",
       "      <td>1075</td>\n",
       "      <td>3023</td>\n",
       "      <td>35.6</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>20220524</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>2727</td>\n",
       "      <td>3023</td>\n",
       "      <td>90.2</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>20220524</td>\n",
       "      <td>open_cur</td>\n",
       "      <td>1706</td>\n",
       "      <td>3023</td>\n",
       "      <td>56.4</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>20220524</td>\n",
       "      <td>reopen_intent</td>\n",
       "      <td>2242</td>\n",
       "      <td>3023</td>\n",
       "      <td>74.2</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20220524</td>\n",
       "      <td>staff_working</td>\n",
       "      <td>1303</td>\n",
       "      <td>3023</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2022-05-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id indicator_code_merged  n_museums  n_sess_museums  \\\n",
       "0    20210304            closed_cur       2253            3018   \n",
       "1    20210304               funding       1115            3018   \n",
       "2    20210304          online_engag       2701            3018   \n",
       "3    20210304              open_cur       1477            3018   \n",
       "4    20210304         reopen_intent       2421            3018   \n",
       "..        ...                   ...        ...             ...   \n",
       "91   20220524               funding       1075            3023   \n",
       "92   20220524          online_engag       2727            3023   \n",
       "93   20220524              open_cur       1706            3023   \n",
       "94   20220524         reopen_intent       2242            3023   \n",
       "95   20220524         staff_working       1303            3023   \n",
       "\n",
       "    indic_museum_pc session_time  \n",
       "0              74.7   2021-03-04  \n",
       "1              36.9   2021-03-04  \n",
       "2              89.5   2021-03-04  \n",
       "3              48.9   2021-03-04  \n",
       "4              80.2   2021-03-04  \n",
       "..              ...          ...  \n",
       "91             35.6   2022-05-24  \n",
       "92             90.2   2022-05-24  \n",
       "93             56.4   2022-05-24  \n",
       "94             74.2   2022-05-24  \n",
       "95             43.1   2022-05-24  \n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus_indic_counts_df = mus_indic_df.groupby(['session_id','indicator_code_merged'], as_index=False).size()\n",
    "mus_indic_counts_df = mus_indic_counts_df.rename(columns={'size':'n_museums'})\n",
    "mus_indic_counts_df = mus_indic_counts_df.merge(mus_indic_unique_df, on='session_id', how='left')\n",
    "\n",
    "mus_indic_counts_df['indic_museum_pc'] = mus_indic_counts_df['n_museums'] / mus_indic_counts_df['n_sess_museums'] * 100\n",
    "mus_indic_counts_df['indic_museum_pc'] = round(mus_indic_counts_df['indic_museum_pc'],1)\n",
    "mus_indic_counts_df['session_time'] = mus_indic_counts_df['session_id'].apply(sessionid_to_time)\n",
    "mus_indic_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot overall indicator trends\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.lineplot(data=mus_indic_counts_df, x=\"session_time\", y=\"n_museums\", markers=True,\n",
    "             hue=\"indicator_code_merged\", style=\"indicator_code_merged\")\n",
    "#[plt.setp(ax.get_xticklabels(), rotation=45) for ax in g.axes.flat]\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "#g.set_xticklabels(g.get_xticklabels()) #, rotation=45, ha='right', rotation_mode='anchor')\n",
    "# move legend outside\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(an_folder+'indicators_over_time-n_museums.pdf',bbox_inches='tight')\n",
    "plt.clf()\n",
    "\n",
    "g = sns.lineplot(data=mus_indic_counts_df, x=\"session_time\", y=\"indic_museum_pc\", markers=True,\n",
    "             hue=\"indicator_code_merged\", style=\"indicator_code_merged\")\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 100)\n",
    "plt.savefig(an_folder+'indicators_over_time-n_museums_pc.pdf',bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load error data\n",
    "err_df = pd.read_excel(out_folder+'data/annotations/indicator_code_stats_validation-v4.xlsx')\n",
    "\n",
    "err_df = select_and_merge_indicators(err_df[['indicator_code','fp','fn']])\n",
    "display(err_df)\n",
    "err_df = err_df[['indicator_code_merged','fn','fp']].groupby('indicator_code_merged').mean()\n",
    "err_df = err_df.reset_index()\n",
    "#err_df.fn = round(err_df.fn*100)\n",
    "#err_df.fp = round(err_df.fp*100)\n",
    "err_df\n",
    "\n",
    "indf = mus_indic_counts_df.copy()\n",
    "#mus_indic_counts_err_df = pd.DataFrame()\n",
    "#mus_indic_counts_err_df['fn'] = 0\n",
    "#mus_indic_counts_err_df['fp'] = 0\n",
    "#print(len(mus_indic_counts_err_df))\n",
    "# upper bound\n",
    "df = indf.merge(err_df, on='indicator_code_merged')\n",
    "print(df.columns)\n",
    "df['factor_upper'] = 1+df['fn']\n",
    "df['n_museums_upper'] = df.n_museums * df.factor_upper\n",
    "#mus_indic_counts_err_df = mus_indic_counts_err_df.append(df)\n",
    "# lower bound\n",
    "#df = indf.merge(err_df, on='indicator_code_merged')\n",
    "print(df.columns)\n",
    "df['factor_lower'] = 1-df['fp']\n",
    "df['n_museums_lower'] = df.n_museums * df.factor_lower\n",
    "mus_indic_counts_err_df = df\n",
    "del df\n",
    "\n",
    "# re-calculate indic_museum_pc\n",
    "mus_indic_counts_err_df['indic_museum_pc'] = mus_indic_counts_err_df['n_museums'] / mus_indic_counts_err_df['n_sess_museums'] * 100\n",
    "mus_indic_counts_err_df['indic_museum_pc_upper'] = mus_indic_counts_err_df['n_museums_upper'] / mus_indic_counts_err_df['n_sess_museums'] * 100\n",
    "mus_indic_counts_err_df['indic_museum_pc_lower'] = mus_indic_counts_err_df['n_museums_lower'] / mus_indic_counts_err_df['n_sess_museums'] * 100\n",
    "#mus_indic_counts_err_df['indic_museum_pc'] = round(mus_indic_counts_err_df['indic_museum_pc'],1)\n",
    "#mus_indic_counts_err_df = mus_indic_counts_err_df.append(mus_indic_counts_df)\n",
    "\n",
    "mus_indic_counts_err_df.to_csv(an_folder + 'total_indicators_w_uncertain.csv', index=False)\n",
    "mus_indic_counts_err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/examples/errorband_lineplots.html\n",
    "#display(mus_indic_counts_err_df)\n",
    "df = mus_indic_counts_err_df[['session_time','indicator_code_merged','n_museums']]\n",
    "display(df)\n",
    "# plot overall indicator trends with error bars\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.lineplot(data=df, x=\"session_time\", y=\"n_museums\", markers=True,\n",
    "             hue=\"indicator_code_merged\", style=\"indicator_code_merged\")\n",
    "#[plt.setp(ax.get_xticklabels(), rotation=45) for ax in g.axes.flat]\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "#g.set_xticklabels(g.get_xticklabels()) #, rotation=45, ha='right', rotation_mode='anchor')\n",
    "# move legend outside\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(an_folder+'indicators_over_time-n_museums_error.pdf', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=mus_indic_counts_err_df, x=\"session_time\", y=\"indic_museum_pc\", markers=True,\n",
    "             hue=\"indicator_code_merged\", style=\"indicator_code_merged\")\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 100)\n",
    "plt.savefig(an_folder+'indicators_over_time-n_museums_pc_error.pdf', bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot indicators over 1 attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['musname', 'muse_id', 'town', 'postcode', 'accreditation', 'governance',\n",
      "       'size', 'subject_matter', 'closing_date', 'provenance',\n",
      "       'deprivation_index', 'geodemographic_group', 'geodemographic_subgroup',\n",
      "       'admin_area'],\n",
      "      dtype='object')\n",
      "loaded museums w attributes (open): 3341 data/museums/museums_wattributes-2020-02-23.tsv\n",
      "independent    2399\n",
      "government      795\n",
      "university       92\n",
      "unknown          55\n",
      "Name: governance_simpl, dtype: int64\n",
      "England             2507\n",
      "Scotland             494\n",
      "Wales                207\n",
      "Northern Ireland      94\n",
      "Channel Islands       24\n",
      "Isle of Man           15\n",
      "Name: country, dtype: int64\n",
      "Scotland                    494\n",
      "South East                  476\n",
      "South West                  422\n",
      "East of England             333\n",
      "North West                  247\n",
      "London                      238\n",
      "Yorkshire and The Humber    229\n",
      "East Midlands               229\n",
      "West Midlands               228\n",
      "Wales                       207\n",
      "North East                  105\n",
      "Northern Ireland             94\n",
      "Channel Islands              24\n",
      "Isle of Man                  15\n",
      "Name: region, dtype: int64\n",
      "Local Histories             764\n",
      "Buildings                   553\n",
      "War and conflict            333\n",
      "Arts                        247\n",
      "Transport                   224\n",
      "Personality                 176\n",
      "Mixed                       166\n",
      "Industry and manufacture    151\n",
      "Rural Industry              111\n",
      "Sea and seafaring           102\n",
      "Belief and identity          96\n",
      "Archaeology                  91\n",
      "Leisure and sport            87\n",
      "Natural world                47\n",
      "Other                        43\n",
      "Services                     34\n",
      "Medicine and health          34\n",
      "Utilities                    33\n",
      "Science and technology       21\n",
      "Food and drink               15\n",
      "Communications               13\n",
      "Name: subject_matter_simpl, dtype: int64\n",
      "df rows= 177417\n",
      "Index(['session_id', 'muse_id', 'indicator_code_merged', 'n_indicator_matches',\n",
      "       'session_time', 'musname', 'town', 'postcode', 'accreditation',\n",
      "       'governance', 'size', 'subject_matter', 'closing_date', 'provenance',\n",
      "       'deprivation_index', 'geodemographic_group', 'geodemographic_subgroup',\n",
      "       'admin_area', 'governance_simpl', 'subject_matter_simpl', 'country',\n",
      "       'region'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaballatore/Dropbox/DRBX_Docs/Work/Projects/github_projects/museums-in-the-pandemic/mip/museums.py:429: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['region'] = df['region'].str.replace(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>muse_id</th>\n",
       "      <th>indicator_code_merged</th>\n",
       "      <th>n_indicator_matches</th>\n",
       "      <th>session_time</th>\n",
       "      <th>musname</th>\n",
       "      <th>town</th>\n",
       "      <th>postcode</th>\n",
       "      <th>accreditation</th>\n",
       "      <th>governance</th>\n",
       "      <th>...</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>provenance</th>\n",
       "      <th>deprivation_index</th>\n",
       "      <th>geodemographic_group</th>\n",
       "      <th>geodemographic_subgroup</th>\n",
       "      <th>admin_area</th>\n",
       "      <th>governance_simpl</th>\n",
       "      <th>subject_matter_simpl</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87323</th>\n",
       "      <td>20210914</td>\n",
       "      <td>mm.fcm.137</td>\n",
       "      <td>staff_working</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>John Jarrold Printing Museum</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>NR3 1SH</td>\n",
       "      <td>Unaccredited</td>\n",
       "      <td>Independent:Private</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>fcm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Larger Towns and Cities</td>\n",
       "      <td>Larger Towns and Cities</td>\n",
       "      <td>/England/East of England (English Region)/Norf...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Industry and manufacture</td>\n",
       "      <td>England</td>\n",
       "      <td>East of England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149972</th>\n",
       "      <td>20220328</td>\n",
       "      <td>mm.domus.SE329</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>18 Stafford Terrace</td>\n",
       "      <td>London</td>\n",
       "      <td>W8 7BH</td>\n",
       "      <td>Unaccredited</td>\n",
       "      <td>Government:Local Authority</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>domus</td>\n",
       "      <td>8.0</td>\n",
       "      <td>London Cosmopolitan</td>\n",
       "      <td>London Cosmopolitan</td>\n",
       "      <td>/England/London (English Region)/Kensington an...</td>\n",
       "      <td>government</td>\n",
       "      <td>Personality</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52208</th>\n",
       "      <td>20210629</td>\n",
       "      <td>mm.domus.SW169</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>24</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>Swanage Museum</td>\n",
       "      <td>Swanage</td>\n",
       "      <td>BH19 2 LJ</td>\n",
       "      <td>Accredited</td>\n",
       "      <td>Independent:Not for profit</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>domus</td>\n",
       "      <td>6.0</td>\n",
       "      <td>English and Welsh Countryside</td>\n",
       "      <td>Older Farming Communities</td>\n",
       "      <td>/England/South West (English Region)/Dorset (E...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Local Histories</td>\n",
       "      <td>England</td>\n",
       "      <td>South West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113237</th>\n",
       "      <td>20220103</td>\n",
       "      <td>mm.ace.1264</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>24</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>RNLI Grace Darling Museum</td>\n",
       "      <td>Bamburgh</td>\n",
       "      <td>NE69 7AE</td>\n",
       "      <td>Accredited</td>\n",
       "      <td>Independent:Not for profit</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>ace</td>\n",
       "      <td>5.0</td>\n",
       "      <td>English and Welsh Countryside</td>\n",
       "      <td>Sparse English and Welsh Countryside</td>\n",
       "      <td>/England/North East (English Region)/North Eas...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Personality</td>\n",
       "      <td>England</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98441</th>\n",
       "      <td>20211108</td>\n",
       "      <td>mm.hha.013</td>\n",
       "      <td>reopen_intent</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>Godinton House</td>\n",
       "      <td>Ashford</td>\n",
       "      <td>TN23 3BP</td>\n",
       "      <td>Unaccredited</td>\n",
       "      <td>Independent:Private</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>hha</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Country Living</td>\n",
       "      <td>Country Living</td>\n",
       "      <td>/England/South East (English Region)/Kent (Eng...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Buildings</td>\n",
       "      <td>England</td>\n",
       "      <td>South East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165123</th>\n",
       "      <td>20220425</td>\n",
       "      <td>mm.musa.042</td>\n",
       "      <td>funding</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>Berkshire Library &amp; Museum Of Freemasonry</td>\n",
       "      <td>Sindlesham</td>\n",
       "      <td>RG41 5EA</td>\n",
       "      <td>Unaccredited</td>\n",
       "      <td>Independent:Not for profit</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>musassoc</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Thriving Rural</td>\n",
       "      <td>Affluent rural</td>\n",
       "      <td>/England/South East (English Region)/Wokingham...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Belief and identity</td>\n",
       "      <td>England</td>\n",
       "      <td>South East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57535</th>\n",
       "      <td>20210712</td>\n",
       "      <td>mm.ace.1122</td>\n",
       "      <td>open_cur</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>Sunnycroft</td>\n",
       "      <td>Telford</td>\n",
       "      <td>TF1 2DR</td>\n",
       "      <td>Accredited</td>\n",
       "      <td>Independent:National Trust</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>ace</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Manufacturing Traits</td>\n",
       "      <td>Urban Living</td>\n",
       "      <td>/England/West Midlands (English Region)/Telfor...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Buildings</td>\n",
       "      <td>England</td>\n",
       "      <td>West Midlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168937</th>\n",
       "      <td>20220524</td>\n",
       "      <td>mm.domus.EM080</td>\n",
       "      <td>staff_working</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>Revolution House</td>\n",
       "      <td>Chesterfield</td>\n",
       "      <td>S41 9JZ</td>\n",
       "      <td>Accredited</td>\n",
       "      <td>Government:Local Authority</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>domus</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Services Manufacturing and Mining Legacy</td>\n",
       "      <td>Manufacturing Legacy</td>\n",
       "      <td>/England/East Midlands (English Region)/Derbys...</td>\n",
       "      <td>government</td>\n",
       "      <td>Buildings</td>\n",
       "      <td>England</td>\n",
       "      <td>East Midlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19882</th>\n",
       "      <td>20210404</td>\n",
       "      <td>mm.hha.026</td>\n",
       "      <td>online_engag</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-04-04</td>\n",
       "      <td>Parham House &amp; Gardens</td>\n",
       "      <td>Pulborough</td>\n",
       "      <td>RH20 4HS</td>\n",
       "      <td>Unaccredited</td>\n",
       "      <td>Independent:Private</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>hha</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Thriving Rural</td>\n",
       "      <td>Rural Growth Areas</td>\n",
       "      <td>/England/South East (English Region)/West Suss...</td>\n",
       "      <td>independent</td>\n",
       "      <td>Buildings</td>\n",
       "      <td>England</td>\n",
       "      <td>South East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149330</th>\n",
       "      <td>20220328</td>\n",
       "      <td>mm.domus.SE094</td>\n",
       "      <td>open_cur</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>Reading Museum</td>\n",
       "      <td>Reading</td>\n",
       "      <td>RG1 1QH</td>\n",
       "      <td>Accredited</td>\n",
       "      <td>Government:Local Authority</td>\n",
       "      <td>...</td>\n",
       "      <td>Still open</td>\n",
       "      <td>domus</td>\n",
       "      <td>4.0</td>\n",
       "      <td>University Towns and Cities</td>\n",
       "      <td>University Towns and Cities</td>\n",
       "      <td>/England/South East (English Region)/Reading (...</td>\n",
       "      <td>government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>England</td>\n",
       "      <td>South East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id         muse_id indicator_code_merged  n_indicator_matches  \\\n",
       "87323    20210914      mm.fcm.137         staff_working                    1   \n",
       "149972   20220328  mm.domus.SE329          online_engag                    2   \n",
       "52208    20210629  mm.domus.SW169          online_engag                   24   \n",
       "113237   20220103     mm.ace.1264          online_engag                   24   \n",
       "98441    20211108      mm.hha.013         reopen_intent                    1   \n",
       "165123   20220425     mm.musa.042               funding                    7   \n",
       "57535    20210712     mm.ace.1122              open_cur                   13   \n",
       "168937   20220524  mm.domus.EM080         staff_working                    1   \n",
       "19882    20210404      mm.hha.026          online_engag                    3   \n",
       "149330   20220328  mm.domus.SE094              open_cur                    2   \n",
       "\n",
       "       session_time                                    musname          town  \\\n",
       "87323    2021-09-14               John Jarrold Printing Museum       Norwich   \n",
       "149972   2022-03-28                        18 Stafford Terrace        London   \n",
       "52208    2021-06-29                             Swanage Museum       Swanage   \n",
       "113237   2022-01-03                  RNLI Grace Darling Museum      Bamburgh   \n",
       "98441    2021-11-08                             Godinton House       Ashford   \n",
       "165123   2022-04-25  Berkshire Library & Museum Of Freemasonry    Sindlesham   \n",
       "57535    2021-07-12                                 Sunnycroft       Telford   \n",
       "168937   2022-05-24                           Revolution House  Chesterfield   \n",
       "19882    2021-04-04                     Parham House & Gardens    Pulborough   \n",
       "149330   2022-03-28                             Reading Museum       Reading   \n",
       "\n",
       "         postcode accreditation                  governance  ... closing_date  \\\n",
       "87323     NR3 1SH  Unaccredited         Independent:Private  ...   Still open   \n",
       "149972     W8 7BH  Unaccredited  Government:Local Authority  ...   Still open   \n",
       "52208   BH19 2 LJ    Accredited  Independent:Not for profit  ...   Still open   \n",
       "113237   NE69 7AE    Accredited  Independent:Not for profit  ...   Still open   \n",
       "98441    TN23 3BP  Unaccredited         Independent:Private  ...   Still open   \n",
       "165123   RG41 5EA  Unaccredited  Independent:Not for profit  ...   Still open   \n",
       "57535     TF1 2DR    Accredited  Independent:National Trust  ...   Still open   \n",
       "168937    S41 9JZ    Accredited  Government:Local Authority  ...   Still open   \n",
       "19882    RH20 4HS  Unaccredited         Independent:Private  ...   Still open   \n",
       "149330    RG1 1QH    Accredited  Government:Local Authority  ...   Still open   \n",
       "\n",
       "       provenance deprivation_index                      geodemographic_group  \\\n",
       "87323         fcm               3.0                   Larger Towns and Cities   \n",
       "149972      domus               8.0                       London Cosmopolitan   \n",
       "52208       domus               6.0             English and Welsh Countryside   \n",
       "113237        ace               5.0             English and Welsh Countryside   \n",
       "98441         hha               6.0                            Country Living   \n",
       "165123   musassoc               9.0                            Thriving Rural   \n",
       "57535         ace               6.0                      Manufacturing Traits   \n",
       "168937      domus               2.0  Services Manufacturing and Mining Legacy   \n",
       "19882         hha               7.0                            Thriving Rural   \n",
       "149330      domus               4.0               University Towns and Cities   \n",
       "\n",
       "                     geodemographic_subgroup  \\\n",
       "87323                Larger Towns and Cities   \n",
       "149972                   London Cosmopolitan   \n",
       "52208              Older Farming Communities   \n",
       "113237  Sparse English and Welsh Countryside   \n",
       "98441                         Country Living   \n",
       "165123                        Affluent rural   \n",
       "57535                           Urban Living   \n",
       "168937                  Manufacturing Legacy   \n",
       "19882                     Rural Growth Areas   \n",
       "149330           University Towns and Cities   \n",
       "\n",
       "                                               admin_area governance_simpl  \\\n",
       "87323   /England/East of England (English Region)/Norf...      independent   \n",
       "149972  /England/London (English Region)/Kensington an...       government   \n",
       "52208   /England/South West (English Region)/Dorset (E...      independent   \n",
       "113237  /England/North East (English Region)/North Eas...      independent   \n",
       "98441   /England/South East (English Region)/Kent (Eng...      independent   \n",
       "165123  /England/South East (English Region)/Wokingham...      independent   \n",
       "57535   /England/West Midlands (English Region)/Telfor...      independent   \n",
       "168937  /England/East Midlands (English Region)/Derbys...       government   \n",
       "19882   /England/South East (English Region)/West Suss...      independent   \n",
       "149330  /England/South East (English Region)/Reading (...       government   \n",
       "\n",
       "            subject_matter_simpl  country           region  \n",
       "87323   Industry and manufacture  England  East of England  \n",
       "149972               Personality  England           London  \n",
       "52208            Local Histories  England       South West  \n",
       "113237               Personality  England       North East  \n",
       "98441                  Buildings  England       South East  \n",
       "165123       Belief and identity  England       South East  \n",
       "57535                  Buildings  England    West Midlands  \n",
       "168937                 Buildings  England    East Midlands  \n",
       "19882                  Buildings  England       South East  \n",
       "149330                     Mixed  England       South East  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mus_indic_df)\n",
    "mdf = load_input_museums_wattributes(out_folder)\n",
    "mdf = get_extra_museum_attributes(mdf)\n",
    "mus_indic_attrib_df = mus_indic_df.merge(mdf, on='muse_id', how='left')\n",
    "print('df rows=',len(mus_indic_attrib_df))\n",
    "print(mus_indic_attrib_df.columns)\n",
    "mus_indic_attrib_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [an_folder+'/indic_pivot_tables/']:\n",
    "    print(x)\n",
    "    if not os.path.exists(x):\n",
    "        os.makedirs(x)\n",
    "\n",
    "def plot_indic_small_mult(df, col, group_var, y_var, y_label, fold):\n",
    "    # plot line chart of indicators (small multiples)\n",
    "    print('plot_indic_small_mult', col, group_var)\n",
    "    g = sns.FacetGrid(df, col=col, col_wrap=6)\n",
    "    g.map_dataframe(sns.lineplot, x=\"session_time\", y=y_var, hue=group_var, style=group_var, marker='.')\n",
    "    if '_pc' in y_var:\n",
    "        plt.ylim(0, 100)\n",
    "    g.add_legend() #loc='lower right')\n",
    "    \n",
    "    # fix up axes and labels\n",
    "    [ax.set(ylabel=y_label) for ax in g.axes.flat]\n",
    "    #for ax in g.axes.flatten():\n",
    "    #    ax.tick_params(labelbottom=True)\n",
    "    [plt.setp(ax.get_xticklabels(), rotation=45, ha='right') for ax in g.axes.flat]\n",
    "    # save figure\n",
    "    figfn = \"{}/indic_linechart-{}-{}-{}.pdf\".format(fold, col, group_var, y_label.lower().replace(' ','_'))\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(figfn,bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    print(figfn)\n",
    "        \n",
    "def pivot_indic_by_attributes(df, col, mus_df):\n",
    "    \"\"\" generate indicators pivoted by attributes \"\"\"\n",
    "    assert col\n",
    "    print(\"> pivot_indic_by_attributes:\",col)\n",
    "    fold = an_folder+'/indic_pivot_tables/indic-'+col+'/'\n",
    "    if not os.path.exists(fold): os.makedirs(fold)\n",
    "    # calc museum totals \n",
    "    mus_counts_df = mus_df.groupby(col).size().to_frame('tot_attr_museums').reset_index()\n",
    "    # fix for size ('size' is reserved in pandas)\n",
    "    print(mus_counts_df.columns)\n",
    "    if 'size' in mus_counts_df.columns:\n",
    "        mus_counts_df = mus_counts_df.rename(columns={'size':'m_size'})\n",
    "        col = 'm_size'\n",
    "    #print(mus_counts_df)\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.rename(columns={'size':'m_size'})\n",
    "    cols = ['session_id','indicator_code_merged']\n",
    "    cols.append(col)\n",
    "    # pivot\n",
    "    piv_df = df.groupby(cols, as_index=False).size()\n",
    "    piv_df = piv_df.merge(mus_counts_df, on=col, how='left')\n",
    "    \n",
    "    piv_df['indic_museum_attr_pc'] = round(piv_df['size'] / piv_df['tot_attr_museums'] * 100,1)\n",
    "    piv_df['session_time'] = piv_df['session_id'].apply(sessionid_to_time)\n",
    "    fn = \"{}/indic_counts-{}.xlsx\".format(fold, col)\n",
    "    print(fn)\n",
    "    piv_df.to_excel(fn, index=False)\n",
    "    \n",
    "    # plot line chart of indicators (small multiples)\n",
    "    # plot 1 by indicators\n",
    "    plot_indic_small_mult(piv_df, 'indicator_code_merged', col, 'size', 'N museums', fold)\n",
    "    plot_indic_small_mult(piv_df, col, 'indicator_code_merged', 'size', 'N museums', fold)\n",
    "    plot_indic_small_mult(piv_df, 'indicator_code_merged', col, 'indic_museum_attr_pc', 'PC museums', fold)\n",
    "    plot_indic_small_mult(piv_df, col, 'indicator_code_merged', 'indic_museum_attr_pc', 'PC museums', fold)\n",
    "    \n",
    "    return piv_df\n",
    "\n",
    "attrib_combs = ['governance_simpl','size','governance','region','country','subject_matter_simpl','accreditation']\n",
    "#attrib_combs = ['accreditation'] # DEBUG\n",
    "for attrs in attrib_combs:\n",
    "    df = pivot_indic_by_attributes(mus_indic_attrib_df, attrs, mdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot indicators over 2 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/analysis/indicators//indic_pivot_tables_2vars/\n"
     ]
    }
   ],
   "source": [
    "fold = an_folder+'/indic_pivot_tables_2vars/'\n",
    "for x in [fold]:\n",
    "    print(x)\n",
    "    if not os.path.exists(x):\n",
    "        os.makedirs(x)\n",
    "        \n",
    "# generate pairs\n",
    "var_combinations = ['subject_matter_simpl','governance','governance_simpl','size','subject_matter',\n",
    "        'accreditation','region','country']\n",
    "var_combinations2 = []\n",
    "for x1 in var_combinations:\n",
    "    for x2 in var_combinations:\n",
    "        if x1 != x2 and (not x2 in x1 and not x1 in x2):\n",
    "            var_combinations2.append([min(x1,x2),max(x1,x2)])\n",
    "for v in var_combinations:\n",
    "    var_combinations2.append([v])\n",
    "    \n",
    "del var_combinations\n",
    "#var_combinations2 = var_combinations2[0:2] # debug\n",
    "#var_combinations2\n",
    "\n",
    "def plot_indic_small_mult_2vars(df, cols, y_var, mus_df, fold):\n",
    "    # plot line chart of indicators (small multiples)\n",
    "    if True:\n",
    "        print('plot_indic_small_mult_2vars', cols)\n",
    "        # line chart grid\n",
    "        #g = sns.FacetGrid(piv2_df, col=cols[2], row=cols[3], margin_titles=True)\n",
    "        g = sns.FacetGrid(df, col=cols[2], row=cols[3], margin_titles=False)\n",
    "        g.map_dataframe(sns.lineplot, x=\"session_time\", y=y_var, hue='indicator_code_merged', style='indicator_code_merged', marker='.')\n",
    "        [plt.setp(ax.get_xticklabels(), rotation=45) for ax in g.axes.flat]\n",
    "        # set extra info in each title\n",
    "        for ax in g.axes.flat:\n",
    "            # m_size = large | region = Channel Islands\n",
    "            tt = ax.get_title().split('|')\n",
    "            var2_val = tt[0].split('=')[1].strip()\n",
    "            var1_val = tt[1].split('=')[1].strip()\n",
    "            assert var1_val\n",
    "            assert var2_val\n",
    "            filt_df = df[(df[cols[2].strip()]==var1_val) & (df[cols[3].strip()]==var2_val)]\n",
    "            n_mus_tot = 0\n",
    "            if len(filt_df) > 0:\n",
    "                n_mus_tot = int(filt_df.n_museum_attrs_tot.tolist()[0])\n",
    "            \n",
    "            ax.set_title(\"{}/\\n{} [n={}]↓\".format(_abbreviate_label(var1_val), _abbreviate_label(var2_val), n_mus_tot))\n",
    "        #g.set_titles(\"{row_name}/{col_name}↓\")\n",
    "        g.add_legend()\n",
    "        g.fig.subplots_adjust(top=0.9)\n",
    "        g.fig.suptitle(\"Indicators over time: '{}' by {} and {} \".format(y_var, cols[2], cols[3]), fontsize=18)\n",
    "        # save figure\n",
    "        figfn = \"{}/indic_linechart_2vars-{}-{}-{}.pdf\".format(fold_var, cols[2], cols[3], y_var)\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "        plt.savefig(figfn, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        print(figfn)\n",
    "    \n",
    "    # heatmap grid\n",
    "    if True:\n",
    "        draw_heatmap_grid(df, cols[2], cols[3], \"session_id\", 'indicator_code_merged', y_var, fold)\n",
    "        draw_heatmap_grid(df, \"session_id\", 'indicator_code_merged', cols[2], cols[3], y_var, fold)\n",
    "\n",
    "def _abbreviate_label(s):\n",
    "    abbr = {'Government':'Gov.', 'Independent':'Indep.', 'Scotland':'Scot.', \n",
    "            'National':'Nat.', 'Environment':'Env.'}\n",
    "    for k,v in abbr.items():\n",
    "        s = s.replace(k,v)\n",
    "    return s\n",
    "        \n",
    "def draw_heatmap_grid(df, grid_col_var, grid_row_var, heat_var1, heat_var2, val_var, fold):\n",
    "    def _draw_heatmap(*args, **kwargs):\n",
    "        data = kwargs.pop('data')\n",
    "        d = data.pivot(index=args[1], columns=args[0], values=args[2])\n",
    "        sns.heatmap(d, **kwargs)\n",
    "        #plt.title('PIACH {} {}'.format(args[0],args[1]))\n",
    "    \n",
    "    figfn = \"{}/indic_heatmap_2vars-{}-{}-{}.pdf\".format(fold, heat_var1, heat_var2, val_var)\n",
    "    g = sns.FacetGrid(piv2_df, col=grid_col_var, row=grid_row_var, margin_titles=False)\n",
    "    min_val = piv2_df[val_var].min()\n",
    "    max_val = piv2_df[val_var].max()\n",
    "    g.map_dataframe(_draw_heatmap, heat_var1, heat_var2, val_var, fmt='g',\n",
    "                    vmin=min_val, vmax=max_val, annot_kws={\"fontsize\":7},\n",
    "                    square=True, cbar=False, annot=True, cmap=\"YlOrBr\")\n",
    "    # fix plot titles\n",
    "    for ax in g.axes.flat:\n",
    "        # m_size = large | region = Channel Islands\n",
    "        tt = ax.get_title().split('|')\n",
    "        var2_val = tt[0].split('=')[1].strip()\n",
    "        var1_val = tt[1].split('=')[1].strip()\n",
    "        assert var1_val\n",
    "        assert var2_val\n",
    "        filt_df = df[(df[grid_col_var]==var1_val) & (df[grid_row_var]==var2_val)]\n",
    "        n_mus_tot = 0\n",
    "        if len(filt_df) > 0:\n",
    "            n_mus_tot = int(filt_df.n_museum_attrs_tot.tolist()[0])\n",
    "        # set title\n",
    "        ax.set_title(\"{}/\\n{} [n={}]↓\".format(_abbreviate_label(var1_val), _abbreviate_label(var2_val), n_mus_tot),\n",
    "                    fontdict={'fontsize': 8, 'fontweight': 'medium'})\n",
    "    g.fig.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(\"Indicators: '{}' per {}/{} (grouped by {} and {})\".format(val_var, heat_var1, heat_var2, grid_row_var, grid_col_var), fontsize=18)\n",
    "    plt.savefig(figfn, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    return figfn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indicator_code_merged', 'session_id', 'm_size', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-subject_matter_simpl/indicators_m_size-subject_matter_simpl_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'm_size', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-subject_matter_simpl/indic_linechart_2vars-m_size-subject_matter_simpl-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'm_size', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-subject_matter_simpl/indic_linechart_2vars-m_size-subject_matter_simpl-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'm_size', 'governance_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-governance_simpl/indicators_m_size-governance_simpl_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'm_size', 'governance_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-governance_simpl/indic_linechart_2vars-m_size-governance_simpl-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'm_size', 'governance_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-governance_simpl/indic_linechart_2vars-m_size-governance_simpl-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'region', 'm_size']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-m_size/indicators_region-m_size_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'region', 'm_size']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-m_size/indic_linechart_2vars-region-m_size-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'region', 'm_size']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-m_size/indic_linechart_2vars-region-m_size-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'region', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-subject_matter_simpl/indicators_region-subject_matter_simpl_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'region', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-subject_matter_simpl/indic_linechart_2vars-region-subject_matter_simpl-n_museums.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaballatore/opt/anaconda3/envs/mip_v1/lib/python3.8/site-packages/seaborn/axisgrid.py:409: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'region', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-subject_matter_simpl/indic_linechart_2vars-region-subject_matter_simpl-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'governance', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/governance-subject_matter_simpl/indicators_governance-subject_matter_simpl_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'governance', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/governance-subject_matter_simpl/indic_linechart_2vars-governance-subject_matter_simpl-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'governance', 'subject_matter_simpl']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/governance-subject_matter_simpl/indic_linechart_2vars-governance-subject_matter_simpl-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'm_size', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-governance/indicators_m_size-governance_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'm_size', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-governance/indic_linechart_2vars-m_size-governance-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'm_size', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/m_size-governance/indic_linechart_2vars-m_size-governance-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'region', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-governance/indicators_region-governance_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'region', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-governance/indic_linechart_2vars-region-governance-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'region', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/region-governance/indic_linechart_2vars-region-governance-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'accreditation', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/accreditation-governance/indicators_accreditation-governance_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'accreditation', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/accreditation-governance/indic_linechart_2vars-accreditation-governance-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'accreditation', 'governance']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/accreditation-governance/indic_linechart_2vars-accreditation-governance-museum_indic_pc.pdf\n",
      "['indicator_code_merged', 'session_id', 'accreditation', 'm_size']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/accreditation-m_size/indicators_accreditation-m_size_counts.xlsx\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'accreditation', 'm_size']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/accreditation-m_size/indic_linechart_2vars-accreditation-m_size-n_museums.pdf\n",
      "plot_indic_small_mult_2vars ['indicator_code_merged', 'session_id', 'accreditation', 'm_size']\n",
      "../../data/analysis/indicators//indic_pivot_tables_2vars/accreditation-m_size/indic_linechart_2vars-accreditation-m_size-museum_indic_pc.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1177.5x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1177.5x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1177.5x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1177.5x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3121.5x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3024x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3121.5x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3024x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3121.5x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3024x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3121.5x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3024x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2905.5x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2808x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2905.5x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2808x4536 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1177.5x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1177.5x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3121.5x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3024x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3121.5x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3024x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 529.5x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 529.5x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x2808 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 529.5x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 529.5x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3456x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_combinations2 = [   \n",
    "    ['m_size','subject_matter_simpl'],['m_size','governance_simpl'],\n",
    "    ['region','m_size'],['region','subject_matter_simpl'],\n",
    "    ['governance','subject_matter_simpl'],\n",
    "    ['m_size','governance'],['region','governance'],\n",
    "    ['accreditation','governance'],['accreditation','m_size']]\n",
    "#var_combinations2 = [['m_size','governance_simpl']]\n",
    "\n",
    "for attrs in var_combinations2:\n",
    "    df = mus_indic_attrib_df.copy()\n",
    "    df = df.rename(columns={'size':'m_size'})\n",
    "    attrs = attrs.copy()\n",
    "    for a in attrs:\n",
    "        df[a] = df[a].str.strip()\n",
    "    attrs.insert(0, 'indicator_code_merged')\n",
    "    attrs.insert(1, 'session_id')\n",
    "    print(attrs)\n",
    "\n",
    "    # create subfolder\n",
    "    fold_var = fold + attrs[2] + '-' + attrs[3]\n",
    "    for x in [fold_var]:        \n",
    "        if not os.path.exists(x):\n",
    "            os.makedirs(x)\n",
    "    # pivot\n",
    "    piv2_df = df.groupby(attrs, as_index=False).size()\n",
    "    piv2_df = piv2_df.rename(columns={'size':'n_museums'})\n",
    "    piv2_df['session_time'] = piv2_df['session_id'].apply(sessionid_to_time)\n",
    "    # add total n of museums in each category\n",
    "    mus_df = mdf.copy().rename(columns={'size':'m_size'})\n",
    "    mus_df['region'] = mus_df.region.str.strip()\n",
    "    counts_mdf = mus_df.groupby([attrs[2],attrs[3]],as_index=False).size()\n",
    "    counts_mdf = counts_mdf.copy().rename(columns={'size':'n_museum_attrs_tot'})\n",
    "    counts_mdf.to_excel(fold_var+'/museum_counts.xlsx',index=False)\n",
    "    for a in attrs[2:3]:\n",
    "        mus_df[a] = mus_df[a].str.strip()\n",
    "    piv2_df = piv2_df.merge(counts_mdf, on=[attrs[2],attrs[3]], how='left')\n",
    "    piv2_df['museum_indic_pc'] = round(piv2_df['n_museums'] / piv2_df['n_museum_attrs_tot'] * 100,1)\n",
    "    #print(piv2_df.head())\n",
    "    #print('testino',piv2_df[(piv2_df['region']=='East Midlands') & (piv2_df['m_size']=='large')]) # DEBUG\n",
    "    #continue\n",
    "    \n",
    "    ex_fn = fold_var+'/indicators_'+attrs[2] + '-' + attrs[3]+'_counts.xlsx'\n",
    "    print(ex_fn)\n",
    "    piv2_df.to_excel(ex_fn, index=False)\n",
    "    # plot\n",
    "    for y_var in ['n_museums','museum_indic_pc']:\n",
    "        plot_indic_small_mult_2vars(piv2_df, attrs, y_var, mdf, fold_var)\n",
    "    os.system('say next')\n",
    "    del piv2_df, attrs\n",
    "                     \n",
    "os.system('say done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicators in social media\n",
    "\n",
    "Analyse indicators in Twitter and Facebook messages, using the same logic developed for websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download social matches from DB (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_columns = ['muse_id','platform','msg_id','ts','page_id','sentence_id',\n",
    "            'example_id','indicator_code','session_id',\n",
    "            'ann_ex_tokens','page_tokens', 'sem_similarity',\n",
    "            'token_n', 'lemma_n', 'ann_overlap_lemma', 'ann_overlap_token',\n",
    "            'example_len', 'txt_overlap_lemma', 'txt_overlap_token', 'ann_overlap_criticwords']\n",
    "\n",
    "sql = \"\"\"select {} from analytics.indicators_social_media_matches t \n",
    "        where keep_stopwords and ann_overlap_criticwords > 0\"\"\".format(','.join(db_columns))\n",
    "\n",
    "i = 1\n",
    "offset = 0\n",
    "chunk_size = 1e6\n",
    "while True:\n",
    "    chunk_sql = sql + \" limit {} offset {}\".format(chunk_size, offset)\n",
    "    \n",
    "    df = pd.read_sql_query(chunk_sql, db_conn)\n",
    "    df = derive_new_attributes_matches(df)\n",
    "    social_matches_fn = out_folder + 'tmp/social_matches_dump_df_{:03d}.pik'.format(i)\n",
    "    print(social_matches_fn)\n",
    "    df.to_pickle(social_matches_fn)\n",
    "    i += 1\n",
    "    print(df.columns)\n",
    "    print(\"matches n =\", len(df), social_matches_fn)\n",
    "    #display(df.sample(20))\n",
    "    offset += chunk_size\n",
    "    if len(df) < chunk_size:\n",
    "        break\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out folder\n",
    "socind_fold = out_folder+'data/analysis/indicators_social/'\n",
    "print('output folder:', socind_fold)\n",
    "if not os.path.exists(socind_fold):\n",
    "    os.makedirs(socind_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Museum match stats for validation\n",
    "\n",
    "The purpose of this validation is to make sure that museums without indicators were processed correctly.\n",
    "Results are in folder `data/analysis/indicators_social/indicators_social_validation`.\n",
    "1094 museums have no social media data (and therefore no matches). \n",
    "1422 museums have at least one social media message and no matches (this is the target of the validation).\n",
    "\n",
    "Twitter ID that contains a match (EM106): 1324349411611287555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_matches_fn = out_folder+'tmp/social_matches_dump_df.pik'\n",
    "match_df = pd.read_pickle(social_matches_fn)\n",
    "print('n',len(match_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get museum attr\n",
    "attr_df = load_input_museums_wattributes(out_folder)\n",
    "attr_df = get_extra_museum_attributes(attr_df)\n",
    "mus_match_df = match_df.groupby('muse_id', as_index=False).size()\n",
    "mus_match_df = mus_match_df.rename(columns={'size':'n_matches'})\n",
    "\n",
    "# join and get museums with zero matches\n",
    "match_attr_df = attr_df.merge(mus_match_df, on='muse_id', how='left')\n",
    "match_attr_df['n_matches'] = match_attr_df.n_matches.fillna(0)\n",
    "display(match_attr_df.sample(10))\n",
    "\n",
    "# get social media counts\n",
    "msg_df = pd.read_excel(out_folder+'data/analysis/social_media_analytics/msg_count_by_museum.xlsx')\n",
    "msg_df = msg_df[['museum_id','msg_count_twitter','msg_count_facebook']]\n",
    "print('msg_df n', len(msg_df))\n",
    "\n",
    "match_attr_df = match_attr_df.merge(msg_df, left_on='muse_id', right_on='museum_id')\n",
    "\n",
    "match_attr_sample_df = match_attr_df.sample(10, random_state=3)\n",
    "display(match_attr_sample_df)\n",
    "\n",
    "missing_match_df = match_attr_df[match_attr_df.n_matches == 0]\n",
    "missing_match_df.to_excel(out_folder+'tmp/social_media_analytics_missing.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict valid social matches\n",
    "\n",
    "Must load `valid_match_cnn_model` before this cell.\n",
    "\n",
    "Total: 28,962,074 matches from social media, of which 1,380,340 valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_matches_fns = glob.glob(out_folder+'tmp/social_matches_dump_df_*.pik')\n",
    "print(social_matches_fns)\n",
    "assert valid_match_cnn_model\n",
    "\n",
    "valid_social_match_df = None\n",
    "\n",
    "for social_matches_fn in sorted(social_matches_fns):\n",
    "    if 'valid' in social_matches_fn:\n",
    "        continue\n",
    "    match_df = pd.read_pickle(social_matches_fn)\n",
    "    match_df = remove_duplicate_matches(match_df)\n",
    "    print(\"\\n\\t\", social_matches_fn, match_df.shape)\n",
    "\n",
    "    # apply model to get valid matches\n",
    "    vdf = select_valid_matches(match_df, valid_match_cnn_model)\n",
    "    vdf = vdf[vdf.valid_match]\n",
    "    \n",
    "    # save results\n",
    "    valid_social_match_df = pd.concat([valid_social_match_df, vdf])\n",
    "    print('valid_social_match_df: ', valid_social_match_df.shape)\n",
    "    del vdf\n",
    "    \n",
    "social_match_df2 = select_and_merge_indicators(valid_social_match_df)\n",
    "social_match_df2 = remove_duplicate_matches(social_match_df2)\n",
    "#social_match_df2.to_csv(socind_fold+'valid_social_matches_dump_df_valid_debug.csv', index=False) # DEBUG\n",
    "all_vmatches_fn = out_folder+'tmp/social_matches_valid.pik'\n",
    "#print(all_vmatches_fn)\n",
    "print(\"valid matches vs invalid\\n\", social_match_df2.valid_match.value_counts())\n",
    "print(\"platforms\\n\", social_match_df2.platform.value_counts())\n",
    "\n",
    "#valdf = social_match_df2[social_match_df2.valid_match]\n",
    "social_match_df2.to_pickle(all_vmatches_fn)\n",
    "print('valid matches:', len(social_match_df2), all_vmatches_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse social media indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vmatches_fn = socind_fold+'social_matches_valid.pik'\n",
    "match_df = pd.read_pickle(all_vmatches_fn)\n",
    "print('valid match_df n =',len(match_df),'from',all_vmatches_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Museum N =\",match_df.muse_id.nunique())\n",
    "print(\"valid matches vs invalid\\n\", match_df.valid_match.value_counts())\n",
    "print(\"platforms\\n\", match_df.platform.value_counts())\n",
    "print(\"indicator_code_merged:\\n\", match_df.indicator_code_merged.value_counts())\n",
    "\n",
    "match_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal analysis of social media indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all indicators\n",
    "time_df = match_df.set_index(pd.DatetimeIndex(match_df['ts']))[['platform','indicator_code_merged']]\n",
    "\n",
    "time_col_grouper = time_df.groupby([pd.Grouper(freq='1W'), 'platform'])\n",
    "time_counts = time_col_grouper['platform'].count().to_frame('count')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(data=time_counts, x=\"ts\", y=\"count\", hue=\"platform\", style='platform')\n",
    "plt.grid()\n",
    "\n",
    "plt.title('All indicators found in social media (weekly)')\n",
    "plt.ylabel('N indicators')\n",
    "plt.xlabel('Time (weeks)')\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "#plt.show()\n",
    "plt.savefig(socind_fold+'socmedia_indic-time_weekly.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by indicator\n",
    "for plat, time_group_df in time_df.groupby('platform'):\n",
    "    \n",
    "    time_col_grouper = time_group_df.groupby([pd.Grouper(freq='1W'), 'indicator_code_merged'])\n",
    "    time_counts = time_col_grouper['indicator_code_merged'].count().to_frame('count')\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.lineplot(data=time_counts, x=\"ts\", y=\"count\", hue=\"indicator_code_merged\", style='indicator_code_merged')\n",
    "    plt.title('All indicators found in {} (weekly)'.format(plat.upper()))\n",
    "    plt.ylabel('N indicators')\n",
    "    plt.xlabel('Time (weeks)')\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=45, horizontalalignment='right')\n",
    "    #plt.show()\n",
    "    plt.savefig(socind_fold+'socmedia_indic-time_weekly-{}.pdf'.format(plat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing websites analysis\n",
    "\n",
    "Analyse museums that do not show online activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = out_folder+'data/analysis/missing_web_soc_museums/'\n",
    "for x in [fold]:\n",
    "    print(x)\n",
    "    if not os.path.exists(x):\n",
    "        os.makedirs(x)\n",
    "        \n",
    "web_df = get_museums_w_web_urls(out_folder)[['muse_id','url','url_source']]\n",
    "#web_df.columns\n",
    "print(len(web_df))\n",
    "attr_df = load_input_museums_wattributes(out_folder)\n",
    "attr_df = get_extra_museum_attributes(attr_df)\n",
    "print(len(attr_df))\n",
    "web_df = web_df.merge(attr_df, on='muse_id', how='outer')\n",
    "web_df = web_df.rename(columns={'muse_id':'museum_id'})\n",
    "soc_df = get_twitter_facebook_links_v2(out_folder)[['museum_id','twitter_id','facebook_pages']]\n",
    "web_df = web_df.merge(soc_df, on='museum_id', how='outer')\n",
    "display(web_df.sample(10))\n",
    "\n",
    "web_df.to_excel(fold+'museums_w_web_social_urls.xlsx', index=False)\n",
    "\n",
    "del soc_df, attr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse missing links\n",
    "print(web_df.url.value_counts())\n",
    "web_df = web_df[web_df['url'] != 'closed']\n",
    "web_df.url.value_counts()\n",
    "\n",
    "web_df['url'].replace('no_resource', np.NaN, inplace=True)\n",
    "web_df.url.value_counts()\n",
    "\n",
    "web_df['b_web'] = ~web_df['url'].isnull()\n",
    "display(web_df.sample(10))\n",
    "web_df['b_web'].value_counts()\n",
    "\n",
    "web_df['twitter_id'].value_counts()\n",
    "web_df['b_twitter'] = web_df['twitter_id'] != 'no_resource'\n",
    "web_df['b_twitter'].value_counts()\n",
    "web_df['b_facebook'] = web_df['facebook_pages'] != 'no_resource'\n",
    "web_df['b_facebook'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_df = web_df.rename(columns={'size':'m_size'})\n",
    "res_df = []\n",
    "for c in ['m_size','governance','governance_simpl','subject_matter_simpl','subject_matter','accreditation','region']:\n",
    "    for var in ['b_web','b_twitter','b_facebook']:\n",
    "        df = web_df.groupby([c,var], as_index=False).size()\n",
    "        df['var1_name'] = c\n",
    "        df['var2_name'] = var\n",
    "        df = df.rename(columns={var:'var2_val'})\n",
    "        df = df.rename(columns={c:'var1_val','size':'n_museums'})\n",
    "        #print(df.columns)\n",
    "        res_df.append(df)\n",
    "res_df = pd.concat(res_df, ignore_index=True)[['var1_name','var1_val','var2_name','var2_val','n_museums']]\n",
    "res_df.to_excel(fold+'missing_web_soc_museum_counts.xlsx', index=False)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = res_df.groupby(['var1_name','var1_val','var2_name'], as_index=False).sum().rename(columns={'n_museums':'tot_museums'})\n",
    "web_res_df = res_df.merge(sum_df[['var1_name','var1_val','var2_name','tot_museums']], on=['var1_name','var1_val','var2_name'], how='outer')\n",
    "web_res_df['museum_pc'] = round(100*web_res_df['n_museums']/web_res_df['tot_museums'],1)\n",
    "web_res_df[~web_res_df.var2_val].to_excel(fold+'missing_web_soc_museum_pc.xlsx', index=False)\n",
    "display(web_res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = web_res_df[~web_res_df.var2_val].pivot(index=['var1_name','var1_val'], columns='var2_name', values='museum_pc').reset_index()\n",
    "wide_df = wide_df.fillna(0).merge(web_res_df[['var1_val','var1_name','tot_museums']], on=['var1_val','var1_name']).drop_duplicates()\n",
    "wide_df.to_excel(fold+'missing_web_soc_museum_wide_pc.xlsx', index=False)\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = web_res_df[~web_res_df.var2_val]\n",
    "for var in ['b_facebook','b_twitter','b_web']:\n",
    "    plt.figure(figsize=(12,22))\n",
    "    p = sns.barplot(data=df[df.var2_name==var].sort_values(['var1_name','museum_pc'], ascending=False), \n",
    "                x='museum_pc', y='var1_val')\n",
    "    plt.title(\"Museum without {} (%)\".format(var.replace('b_','').replace('web','website')))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fold+'missing_web_soc_museum-barchart-{}.pdf'.format(var))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Website size analysis\n",
    "\n",
    "Analyse numer of pages and sizes and deltas of museum websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from analytics.website_sizes;\"\n",
    "websz_df = pd.read_sql(sql, db_conn)\n",
    "websz_df = websz_df.drop(columns='index')\n",
    "print(len(websz_df))\n",
    "display(websz_df.sample(5))\n",
    "\n",
    "#for c in ['page_text_words', 'html_page_content_length', 'sum_links_words','links_level1']:\n",
    "#    websz_df[c] = df[c].fillna(0)\n",
    "\n",
    "print(\"Museums N:\",websz_df.museum_id.nunique())\n",
    "print(\"Sessions N:\",websz_df.session_id.nunique())\n",
    "\n",
    "sz_fold = out_folder + 'data/analysis/website_sizes/'\n",
    "print(sz_fold)\n",
    "if not os.path.exists(sz_fold): os.makedirs(sz_fold)\n",
    "if not os.path.exists(sz_fold+'websize_attribute_barcharts'): os.makedirs(sz_fold+'websize_attribute_barcharts')\n",
    "\n",
    "websz_df.to_excel(sz_fold+'website_sizes.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_str = \"\"\"\n",
    "Analysis of size of museum websites:\n",
    "\n",
    "10 snapshots are considered.\n",
    "\n",
    "* website_size_by_attribute-mean.xlsx: mean of web sizes by museum attributes\n",
    "\n",
    "Fields:\n",
    "* page_text_len: length of plain text in the main web page (n characters)\n",
    "* page_text_words: number of words in plain text in the main web page\n",
    "* page_html_len: length of HTML code in the main web page (n characters)\n",
    "* links_level1: number of links in the main page\n",
    "* sum_links_length: sum of lenghts of plain text pages linked from main page (n characters)\n",
    "* sum_links_words: sum of lenghts plain text pages linked from main page (n of words)\n",
    "\"\"\"\n",
    "write_file(doc_str, sz_fold+'data_dictionary-website_sizes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websz_df.page_html_len.hist(bins=30)\n",
    "plt.xlabel('HTML page length')\n",
    "plt.ylabel('N museums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websz_df.page_html_len.hist(bins=30, log=True)\n",
    "plt.xlabel('HTML page length')\n",
    "plt.ylabel('N museums (log)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websz_df.links_level1.hist(bins=30)\n",
    "plt.xlabel('Links N')\n",
    "plt.ylabel('N museums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websz_df.links_level1.hist(bins=30, log=True)\n",
    "plt.xlabel('Links N')\n",
    "plt.ylabel('N museums (log)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: too many museums\n",
    "for col in ['page_text_words', 'page_html_len', 'sum_links_words','links_level1']:\n",
    "    g = sns.FacetGrid(websz_df.sample(10), col='museum_name', col_wrap=4)\n",
    "    g.map_dataframe(sns.lineplot, x=\"session_time\", y=col) #, hue=group_var, style=group_var, marker='.')\n",
    "    g.add_legend() #loc='lower right')\n",
    "    #[ax.set(ylabel='') for ax in g.axes.flat]\n",
    "    [plt.setp(ax.get_xticklabels(), rotation=45, ha='right') for ax in g.axes.flat]\n",
    "    fn = '{}website_sizes-by_museum-{}.pdf'.format(sz_fold, col)\n",
    "    plt.savefig(fn,bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizes by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get museum attributes\n",
    "attr_df = get_extra_museum_attributes(load_input_museums_wattributes(out_folder))\n",
    "webdf = get_museums_w_web_urls(out_folder)[['muse_id','url']]\n",
    "\n",
    "attr_df = attr_df.merge(webdf, on='muse_id')\n",
    "websz_att_df = pd.merge(websz_df, attr_df, left_on='museum_id', right_on='muse_id', how='left')\n",
    "\n",
    "print(websz_att_df.columns)\n",
    "\n",
    "# Summary of sizes per museum\n",
    "websz_mus_df = websz_df.groupby('museum_id',as_index=False).mean().round(1).drop(columns=['page_id'])\n",
    "websz_mus_df = pd.merge(websz_mus_df, attr_df, left_on='museum_id', right_on='muse_id', how='left')\n",
    "for field in ['page_text_words','page_html_len','links_level1','sum_links_length','sum_links_words']:\n",
    "    websz_mus_df[field+'_z'] = round((websz_mus_df[field] - websz_mus_df[field].mean())/websz_mus_df[field].std(),3)\n",
    "        \n",
    "websz_mus_df.to_excel(sz_fold+'website_size_by_museum-mean.xlsx', index=False)\n",
    "print(len(websz_mus_df))\n",
    "websz_mus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def websize_stat(stat):\n",
    "    # group by categories\n",
    "    df = pd.DataFrame()\n",
    "    for v in ['governance','governance_simpl','size','subject_matter_simpl','region','accreditation']:\n",
    "        if stat == 'mean':\n",
    "            meandf = websz_att_df.groupby(v, as_index=False).mean().round(1)\n",
    "        if stat == 'std':\n",
    "            meandf = websz_att_df.groupby(v, as_index=False).std().round(1)\n",
    "        meandf['val'] = v + ' > ' + meandf[v]\n",
    "        meandf['var'] = v\n",
    "        meandf = meandf.drop(columns=[v,'page_id','deprivation_index'])\n",
    "        # get z scores\n",
    "        for field in meandf.columns.drop(['val','var']):\n",
    "            meandf[field+'_z'] = round((meandf[field] - meandf[field].mean())/meandf[field].std(),3)\n",
    "            \n",
    "            # plots\n",
    "            ax = sns.barplot(x=field, y=v, data=websz_att_df)\n",
    "            fn = \"{}/websize_attribute_barcharts/websize_barchart-{}-{}.pdf\".format(sz_fold,v,field)\n",
    "            plt.title('Analysis of website sizes by {} ({})'.format(v, stat))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fn)\n",
    "            plt.clf()\n",
    "            \n",
    "        # change col order    \n",
    "        col = meandf.pop(\"val\")\n",
    "        meandf.insert(0, col.name, col)\n",
    "        col = meandf.pop(\"var\")\n",
    "        meandf.insert(0, col.name, col)\n",
    "        df = df.append(meandf)\n",
    "    \n",
    "    df.to_excel(sz_fold+'website_size_by_attribute-{}.xlsx'.format(stat),index=False)\n",
    "    df\n",
    "\n",
    "websize_stat('mean')\n",
    "websize_stat('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check zero cases\n",
    "\n",
    "13/160*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
